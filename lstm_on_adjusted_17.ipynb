{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11454359,"sourceType":"datasetVersion","datasetId":7176952}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport sys\nimport os\n# from sklearn.preprocessing import MinMaxScaler","metadata":{"_uuid":"9065264c-521f-4391-bad9-f91f83c0d138","_cell_guid":"3c10ea55-58b0-4a52-b037-f8ff2e7c6463","trusted":true,"collapsed":false,"id":"rzuiw21qCLmj","executionInfo":{"status":"ok","timestamp":1744928258863,"user_tz":-240,"elapsed":1237,"user":{"displayName":"Vahagn Dovlatyan Univ 2","userId":"09643611316529200036"}},"execution":{"iopub.status.busy":"2025-04-18T01:15:41.979101Z","iopub.execute_input":"2025-04-18T01:15:41.979965Z","iopub.status.idle":"2025-04-18T01:15:42.294057Z","shell.execute_reply.started":"2025-04-18T01:15:41.979925Z","shell.execute_reply":"2025-04-18T01:15:42.293550Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Run before importing torch. This is for cuda memory allocation error. Doesn't fix it tho.\nos.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"","metadata":{"_uuid":"794f43c3-f762-4943-8d45-efe9f299d060","_cell_guid":"c0df7160-e7ec-407e-9cea-164f7e0433cc","trusted":true,"collapsed":false,"id":"y7GDRca2Weg1","executionInfo":{"status":"ok","timestamp":1744929937946,"user_tz":-240,"elapsed":2,"user":{"displayName":"Vahagn Dovlatyan Univ 2","userId":"09643611316529200036"}},"execution":{"iopub.status.busy":"2025-04-18T01:15:43.920623Z","iopub.execute_input":"2025-04-18T01:15:43.920984Z","iopub.status.idle":"2025-04-18T01:15:43.924721Z","shell.execute_reply.started":"2025-04-18T01:15:43.920964Z","shell.execute_reply":"2025-04-18T01:15:43.924079Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader","metadata":{"_uuid":"1abb8f5e-b48c-42d0-9dae-a19bb0ca8129","_cell_guid":"6c43ae44-a915-43b0-ad64-1581932333e6","trusted":true,"collapsed":false,"id":"pSh1qcEkCwmE","executionInfo":{"status":"ok","timestamp":1744929943425,"user_tz":-240,"elapsed":3421,"user":{"displayName":"Vahagn Dovlatyan Univ 2","userId":"09643611316529200036"}},"execution":{"iopub.status.busy":"2025-04-18T01:15:45.226622Z","iopub.execute_input":"2025-04-18T01:15:45.227622Z","iopub.status.idle":"2025-04-18T01:15:46.829313Z","shell.execute_reply.started":"2025-04-18T01:15:45.227583Z","shell.execute_reply":"2025-04-18T01:15:46.828774Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"_uuid":"fb8a0562-54b0-4c73-9491-dd8a37ce1389","_cell_guid":"c4251c6d-5953-4346-94bf-3571633e3ca8","trusted":true,"collapsed":false,"id":"X2qxGcCxOMAd","executionInfo":{"status":"ok","timestamp":1744929954439,"user_tz":-240,"elapsed":13,"user":{"displayName":"Vahagn Dovlatyan Univ 2","userId":"09643611316529200036"}},"outputId":"93580dcb-3498-4184-b4cc-60b05ced0180","execution":{"iopub.status.busy":"2025-04-18T01:15:48.188649Z","iopub.execute_input":"2025-04-18T01:15:48.189339Z","iopub.status.idle":"2025-04-18T01:15:48.247020Z","shell.execute_reply.started":"2025-04-18T01:15:48.189316Z","shell.execute_reply":"2025-04-18T01:15:48.246186Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# For Colab\nfrom google.colab import drive\ndrive.mount('/content/drive')\nsys.path.append(\"/content/drive/MyDrive/Diplom/\")","metadata":{"_uuid":"63205616-9520-446a-bc1f-c591d38af3e4","_cell_guid":"ed72ec80-03c8-4185-a355-0962d913ebc6","trusted":true,"collapsed":false,"id":"hjiFNjOnCxD-","executionInfo":{"status":"ok","timestamp":1744929974691,"user_tz":-240,"elapsed":18713,"user":{"displayName":"Vahagn Dovlatyan Univ 2","userId":"09643611316529200036"}},"outputId":"eccb2a04-0d52-46f6-c28b-67a517b62301","jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# For Colab\ndf = pd.read_csv(\"/content/drive/MyDrive/Diplom/data/close_adjusted_17.csv\")","metadata":{"_uuid":"a38fc1b6-f5ba-4c6f-aef7-826435dde5e8","_cell_guid":"a41c9380-476b-4613-a95b-07159c7b5e7f","trusted":true,"collapsed":false,"id":"pVT2D04HE-Du","executionInfo":{"status":"ok","timestamp":1744929977520,"user_tz":-240,"elapsed":2827,"user":{"displayName":"Vahagn Dovlatyan Univ 2","userId":"09643611316529200036"}},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# For Kaggle\ndf = pd.read_csv(\"/kaggle/input/stock-prices-dataset/data/close_adjusted_17.csv\")","metadata":{"_uuid":"0f7a3458-5e6c-41b1-9d1a-ca04cd9db82f","_cell_guid":"856ff073-0e6e-460d-afa9-ae9ffee8cc9e","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-04-18T01:15:56.760721Z","iopub.execute_input":"2025-04-18T01:15:56.761463Z","iopub.status.idle":"2025-04-18T01:15:57.275776Z","shell.execute_reply.started":"2025-04-18T01:15:56.761436Z","shell.execute_reply":"2025-04-18T01:15:57.275176Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Cleaning dataframe.","metadata":{"_uuid":"9648a4ab-c701-44b3-a903-7f13cec91eb6","_cell_guid":"9074c38c-9fd9-45f8-bc7b-d8ee24231323","trusted":true,"collapsed":false,"id":"N64yTwecEHtU","jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Convert 'date' to datetime\ndf[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\")\n\n# Set 'date' as index\ndf.set_index(\"date\", inplace=True)\n\n#Getting rid of missing values\ndf = df.ffill().bfill()","metadata":{"_uuid":"dd6ef9bb-0c18-4f51-a161-4559655d833c","_cell_guid":"2c092f5e-a94c-4ceb-affc-e88c2baeb931","trusted":true,"collapsed":false,"id":"Ap-YtumCEHAV","executionInfo":{"status":"ok","timestamp":1744929977586,"user_tz":-240,"elapsed":64,"user":{"displayName":"Vahagn Dovlatyan Univ 2","userId":"09643611316529200036"}},"execution":{"iopub.status.busy":"2025-04-18T01:16:00.382857Z","iopub.execute_input":"2025-04-18T01:16:00.383546Z","iopub.status.idle":"2025-04-18T01:16:00.460918Z","shell.execute_reply.started":"2025-04-18T01:16:00.383520Z","shell.execute_reply":"2025-04-18T01:16:00.460116Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.shape","metadata":{"_uuid":"ae39839c-9536-46e3-a496-fe08dac6e857","_cell_guid":"1f045e7d-aa88-4426-a9b0-9ea2c51b7399","trusted":true,"collapsed":false,"id":"0kRuMNdvERc0","executionInfo":{"status":"ok","timestamp":1744929977593,"user_tz":-240,"elapsed":5,"user":{"displayName":"Vahagn Dovlatyan Univ 2","userId":"09643611316529200036"}},"outputId":"25d37ea8-ca29-4eb2-9d40-0338d082884a","execution":{"iopub.status.busy":"2025-04-18T01:18:13.005823Z","iopub.execute_input":"2025-04-18T01:18:13.006155Z","iopub.status.idle":"2025-04-18T01:18:13.011133Z","shell.execute_reply.started":"2025-04-18T01:18:13.006134Z","shell.execute_reply":"2025-04-18T01:18:13.010573Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"(4378, 505)"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"# Train Data: 2006-2017\ntrain_prices = df.loc[:'2017']\n\n# Validation Data: 2018\nval_prices = df.loc['2018']\n\n# Test Data: 2019 onward\ntest_prices = df.loc['2019':]","metadata":{"_uuid":"8fb9488e-c2f7-4533-a337-20c1262c93c9","_cell_guid":"79f57088-fd1e-45dd-825f-834e10491ab7","trusted":true,"collapsed":false,"id":"g8YCV391IRau","executionInfo":{"status":"ok","timestamp":1744929977617,"user_tz":-240,"elapsed":23,"user":{"displayName":"Vahagn Dovlatyan Univ 2","userId":"09643611316529200036"}},"execution":{"iopub.status.busy":"2025-04-18T01:19:02.746889Z","iopub.execute_input":"2025-04-18T01:19:02.747594Z","iopub.status.idle":"2025-04-18T01:19:02.753493Z","shell.execute_reply.started":"2025-04-18T01:19:02.747573Z","shell.execute_reply":"2025-04-18T01:19:02.752688Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"train_returns = ((train_prices - train_prices.shift(1)) / train_prices.shift(1)).iloc[1:]\nval_returns = ((val_prices - val_prices.shift(1)) / val_prices.shift(1)).iloc[1:]\ntest_returns = ((test_prices - test_prices.shift(1)) / test_prices.shift(1)).iloc[1:]","metadata":{"_uuid":"36216f28-6b73-48db-96a5-29e2e306dd71","_cell_guid":"52329cfc-02c3-4693-a5a1-bd003d0743ab","trusted":true,"collapsed":false,"id":"SmB_D9SHIuzf","executionInfo":{"status":"ok","timestamp":1744929977636,"user_tz":-240,"elapsed":16,"user":{"displayName":"Vahagn Dovlatyan Univ 2","userId":"09643611316529200036"}},"execution":{"iopub.status.busy":"2025-04-18T01:19:04.378747Z","iopub.execute_input":"2025-04-18T01:19:04.379430Z","iopub.status.idle":"2025-04-18T01:19:04.402257Z","shell.execute_reply.started":"2025-04-18T01:19:04.379406Z","shell.execute_reply":"2025-04-18T01:19:04.401667Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"train_prices.shape, val_prices.shape, test_prices.shape","metadata":{"_uuid":"f77e4712-63a9-4652-9674-525ae30edb04","_cell_guid":"aeeab543-3670-4d7c-b80a-0fa2385e23c8","trusted":true,"collapsed":false,"id":"Z8X8-7INIZ0l","executionInfo":{"status":"ok","timestamp":1744929977662,"user_tz":-240,"elapsed":22,"user":{"displayName":"Vahagn Dovlatyan Univ 2","userId":"09643611316529200036"}},"outputId":"c2cffb01-c1be-40c0-99ff-235d4b88a38e","execution":{"iopub.status.busy":"2025-04-18T01:19:05.533796Z","iopub.execute_input":"2025-04-18T01:19:05.534073Z","iopub.status.idle":"2025-04-18T01:19:05.539293Z","shell.execute_reply.started":"2025-04-18T01:19:05.534053Z","shell.execute_reply":"2025-04-18T01:19:05.538604Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"((3019, 505), (251, 505), (1108, 505))"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"train_returns.shape, val_returns.shape, test_returns.shape","metadata":{"_uuid":"9e32c66b-4ab2-44db-858f-42648d4e0d1a","_cell_guid":"9add8266-5230-4a4e-baf8-9fd192cc02c5","trusted":true,"collapsed":false,"id":"OGLhd4pCJdQw","executionInfo":{"status":"ok","timestamp":1744929977677,"user_tz":-240,"elapsed":5,"user":{"displayName":"Vahagn Dovlatyan Univ 2","userId":"09643611316529200036"}},"outputId":"f59ef891-4521-4219-c465-7df317218677","execution":{"iopub.status.busy":"2025-04-18T01:19:06.567668Z","iopub.execute_input":"2025-04-18T01:19:06.567944Z","iopub.status.idle":"2025-04-18T01:19:06.573055Z","shell.execute_reply.started":"2025-04-18T01:19:06.567925Z","shell.execute_reply":"2025-04-18T01:19:06.572433Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"((3018, 505), (250, 505), (1107, 505))"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"train_returns.describe()","metadata":{"_uuid":"379b3ebd-325d-44f5-b3fe-d1bd70f4fa82","_cell_guid":"9dddbbe4-4615-4885-aa24-8f086a766f5d","trusted":true,"collapsed":false,"id":"vh-vTl1nU7nC","executionInfo":{"status":"ok","timestamp":1744929978785,"user_tz":-240,"elapsed":1107,"user":{"displayName":"Vahagn Dovlatyan Univ 2","userId":"09643611316529200036"}},"outputId":"c1bdf9cc-d126-4532-c504-83ecf9847e2a","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-04-18T01:19:07.742663Z","iopub.execute_input":"2025-04-18T01:19:07.743344Z","iopub.status.idle":"2025-04-18T01:19:08.347004Z","shell.execute_reply.started":"2025-04-18T01:19:07.743323Z","shell.execute_reply":"2025-04-18T01:19:08.346276Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"        CSCO.close    UAL.close   TROW.close   ISRG.close   PRGO.close  \\\ncount  3018.000000  3018.000000  3018.000000  3018.000000  3018.000000   \nmean      0.000485     0.001095     0.000724     0.001055     0.000807   \nstd       0.018361     0.043495     0.023482     0.025874     0.020220   \nmin      -0.162109    -0.367709    -0.179387    -0.172167    -0.211412   \n25%      -0.007253    -0.016508    -0.008911    -0.009461    -0.008821   \n50%       0.000454     0.000000     0.000373     0.000420     0.000972   \n75%       0.008605     0.018270     0.009733     0.010863     0.010798   \nmax       0.159501     0.685371     0.181666     0.323227     0.183899   \n\n         TPR.close    DVN.close    MRO.close     BA.close   VRTX.close  ...  \\\ncount  3018.000000  3018.000000  3018.000000  3018.000000  3018.000000  ...   \nmean      0.000468     0.000205     0.000399     0.000720     0.001051  ...   \nstd       0.024315     0.025126     0.027014     0.017455     0.032835  ...   \nmin      -0.185706    -0.166888    -0.195645    -0.089290    -0.166782  ...   \n25%      -0.010933    -0.012409    -0.012472    -0.008048    -0.014017  ...   \n50%       0.000343     0.000000     0.000566     0.001012    -0.000686  ...   \n75%       0.011278     0.013070     0.013846     0.009534     0.014913  ...   \nmax       0.204482     0.214667     0.233562     0.154628     0.619066  ...   \n\n         TSS.close    CRM.close    PGR.close    WAT.close    BWA.close  \\\ncount  3018.000000  3018.000000  3018.000000  3018.000000  3018.000000   \nmean      0.000607     0.001160     0.000498     0.000702     0.000720   \nstd       0.017248     0.026764     0.017207     0.017925     0.024140   \nmin      -0.147391    -0.184533    -0.130179    -0.200055    -0.136625   \n25%      -0.006953    -0.011650    -0.007035    -0.007042    -0.010358   \n50%       0.000743     0.000206     0.000434     0.000725     0.000470   \n75%       0.008583     0.013232     0.007974     0.008612     0.011899   \nmax       0.131648     0.191308     0.239742     0.162599     0.228278   \n\n        LRCX.close    NWL.close    UAA.close    BLK.close    PPL.close  \ncount  3018.000000  3018.000000  3018.000000  3018.000000  3018.000000  \nmean      0.000830     0.000417     0.000894     0.000862     0.000306  \nstd       0.023793     0.021565     0.030767     0.022711     0.014213  \nmin      -0.146129    -0.273147    -0.257429    -0.155242    -0.131840  \n25%      -0.011577    -0.008430    -0.013939    -0.008698    -0.006395  \n50%       0.000787     0.000330     0.000879     0.000306     0.000799  \n75%       0.013214     0.009296     0.015506     0.010610     0.007459  \nmax       0.151911     0.205310     0.263383     0.195609     0.148006  \n\n[8 rows x 505 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CSCO.close</th>\n      <th>UAL.close</th>\n      <th>TROW.close</th>\n      <th>ISRG.close</th>\n      <th>PRGO.close</th>\n      <th>TPR.close</th>\n      <th>DVN.close</th>\n      <th>MRO.close</th>\n      <th>BA.close</th>\n      <th>VRTX.close</th>\n      <th>...</th>\n      <th>TSS.close</th>\n      <th>CRM.close</th>\n      <th>PGR.close</th>\n      <th>WAT.close</th>\n      <th>BWA.close</th>\n      <th>LRCX.close</th>\n      <th>NWL.close</th>\n      <th>UAA.close</th>\n      <th>BLK.close</th>\n      <th>PPL.close</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>3018.000000</td>\n      <td>3018.000000</td>\n      <td>3018.000000</td>\n      <td>3018.000000</td>\n      <td>3018.000000</td>\n      <td>3018.000000</td>\n      <td>3018.000000</td>\n      <td>3018.000000</td>\n      <td>3018.000000</td>\n      <td>3018.000000</td>\n      <td>...</td>\n      <td>3018.000000</td>\n      <td>3018.000000</td>\n      <td>3018.000000</td>\n      <td>3018.000000</td>\n      <td>3018.000000</td>\n      <td>3018.000000</td>\n      <td>3018.000000</td>\n      <td>3018.000000</td>\n      <td>3018.000000</td>\n      <td>3018.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.000485</td>\n      <td>0.001095</td>\n      <td>0.000724</td>\n      <td>0.001055</td>\n      <td>0.000807</td>\n      <td>0.000468</td>\n      <td>0.000205</td>\n      <td>0.000399</td>\n      <td>0.000720</td>\n      <td>0.001051</td>\n      <td>...</td>\n      <td>0.000607</td>\n      <td>0.001160</td>\n      <td>0.000498</td>\n      <td>0.000702</td>\n      <td>0.000720</td>\n      <td>0.000830</td>\n      <td>0.000417</td>\n      <td>0.000894</td>\n      <td>0.000862</td>\n      <td>0.000306</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.018361</td>\n      <td>0.043495</td>\n      <td>0.023482</td>\n      <td>0.025874</td>\n      <td>0.020220</td>\n      <td>0.024315</td>\n      <td>0.025126</td>\n      <td>0.027014</td>\n      <td>0.017455</td>\n      <td>0.032835</td>\n      <td>...</td>\n      <td>0.017248</td>\n      <td>0.026764</td>\n      <td>0.017207</td>\n      <td>0.017925</td>\n      <td>0.024140</td>\n      <td>0.023793</td>\n      <td>0.021565</td>\n      <td>0.030767</td>\n      <td>0.022711</td>\n      <td>0.014213</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>-0.162109</td>\n      <td>-0.367709</td>\n      <td>-0.179387</td>\n      <td>-0.172167</td>\n      <td>-0.211412</td>\n      <td>-0.185706</td>\n      <td>-0.166888</td>\n      <td>-0.195645</td>\n      <td>-0.089290</td>\n      <td>-0.166782</td>\n      <td>...</td>\n      <td>-0.147391</td>\n      <td>-0.184533</td>\n      <td>-0.130179</td>\n      <td>-0.200055</td>\n      <td>-0.136625</td>\n      <td>-0.146129</td>\n      <td>-0.273147</td>\n      <td>-0.257429</td>\n      <td>-0.155242</td>\n      <td>-0.131840</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>-0.007253</td>\n      <td>-0.016508</td>\n      <td>-0.008911</td>\n      <td>-0.009461</td>\n      <td>-0.008821</td>\n      <td>-0.010933</td>\n      <td>-0.012409</td>\n      <td>-0.012472</td>\n      <td>-0.008048</td>\n      <td>-0.014017</td>\n      <td>...</td>\n      <td>-0.006953</td>\n      <td>-0.011650</td>\n      <td>-0.007035</td>\n      <td>-0.007042</td>\n      <td>-0.010358</td>\n      <td>-0.011577</td>\n      <td>-0.008430</td>\n      <td>-0.013939</td>\n      <td>-0.008698</td>\n      <td>-0.006395</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.000454</td>\n      <td>0.000000</td>\n      <td>0.000373</td>\n      <td>0.000420</td>\n      <td>0.000972</td>\n      <td>0.000343</td>\n      <td>0.000000</td>\n      <td>0.000566</td>\n      <td>0.001012</td>\n      <td>-0.000686</td>\n      <td>...</td>\n      <td>0.000743</td>\n      <td>0.000206</td>\n      <td>0.000434</td>\n      <td>0.000725</td>\n      <td>0.000470</td>\n      <td>0.000787</td>\n      <td>0.000330</td>\n      <td>0.000879</td>\n      <td>0.000306</td>\n      <td>0.000799</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.008605</td>\n      <td>0.018270</td>\n      <td>0.009733</td>\n      <td>0.010863</td>\n      <td>0.010798</td>\n      <td>0.011278</td>\n      <td>0.013070</td>\n      <td>0.013846</td>\n      <td>0.009534</td>\n      <td>0.014913</td>\n      <td>...</td>\n      <td>0.008583</td>\n      <td>0.013232</td>\n      <td>0.007974</td>\n      <td>0.008612</td>\n      <td>0.011899</td>\n      <td>0.013214</td>\n      <td>0.009296</td>\n      <td>0.015506</td>\n      <td>0.010610</td>\n      <td>0.007459</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>0.159501</td>\n      <td>0.685371</td>\n      <td>0.181666</td>\n      <td>0.323227</td>\n      <td>0.183899</td>\n      <td>0.204482</td>\n      <td>0.214667</td>\n      <td>0.233562</td>\n      <td>0.154628</td>\n      <td>0.619066</td>\n      <td>...</td>\n      <td>0.131648</td>\n      <td>0.191308</td>\n      <td>0.239742</td>\n      <td>0.162599</td>\n      <td>0.228278</td>\n      <td>0.151911</td>\n      <td>0.205310</td>\n      <td>0.263383</td>\n      <td>0.195609</td>\n      <td>0.148006</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 505 columns</p>\n</div>"},"metadata":{}}],"execution_count":18},{"cell_type":"markdown","source":"Dataloader construction.","metadata":{"_uuid":"f6601407-ed5f-4ec4-a628-178794460f57","_cell_guid":"8bf642bb-0dfe-4fde-bac4-5bb18c04bb7a","trusted":true,"collapsed":false,"id":"fJ9NulVyLB1N","jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"class StockDataset(Dataset):\n    def __init__(self, returns_df, prices_df, window_size=100, sharpe_window=10):\n        \"\"\"\n        returns_df: pandas DataFrame (days, 505) - daily returns\n        prices_df: pandas DataFrame (days, 505) - daily prices\n        window_size: T (sequence length for LSTM)\n        sharpe_window: R (periods over which to compute Sharpe)\n        \"\"\"\n        assert returns_df.shape == prices_df.shape, \"DataFrames must be same shape\"\n        self.returns = torch.tensor(returns_df.values, dtype=torch.float32)  # (2767, 505)\n        self.prices = torch.tensor(prices_df.values, dtype=torch.float32)    # (2767, 505)\n\n        self.T = window_size\n        self.R = sharpe_window\n        self.S = returns_df.shape[1]\n        self.F = 2  # returns + prices\n        self.max_start = len(returns_df) - self.R - self.T + 1\n\n    def __len__(self):\n        return self.max_start\n\n    def __getitem__(self, idx):\n        \"\"\"\n        Returns:\n            x: (R, T, S, 2) - [returns, prices]\n            y: (R, S) - next-day returns\n        \"\"\"\n        x = []\n        y = []\n        for r in range(self.R):\n            start = idx + r\n            end = start + self.T\n\n            ret_window = self.returns[start:end]  # (T, S)\n            pri_window = self.prices[start:end]   # (T, S)\n\n            window = torch.stack([ret_window, pri_window], dim=-1)  # (T, S, 2)\n            x.append(window)\n            y.append(self.returns[start + self.T])  # Next-day returns\n\n        x = torch.stack(x)  # (R, T, S, 2)\n        y = torch.stack(y)  # (R, S)\n        return x, y","metadata":{"_uuid":"803a2976-0025-4fa2-a5b1-b1fbf92dc479","_cell_guid":"137c31b1-3183-45cb-90fb-ef2e381abd27","trusted":true,"collapsed":false,"id":"3H8UzNLq6T-e","executionInfo":{"status":"ok","timestamp":1744929978790,"user_tz":-240,"elapsed":10,"user":{"displayName":"Vahagn Dovlatyan Univ 2","userId":"09643611316529200036"}},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-04-18T01:19:14.679942Z","iopub.execute_input":"2025-04-18T01:19:14.680201Z","iopub.status.idle":"2025-04-18T01:19:14.687243Z","shell.execute_reply.started":"2025-04-18T01:19:14.680182Z","shell.execute_reply":"2025-04-18T01:19:14.686447Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"B = 8 # batch size\nR = 30 # sharpe window\nT = 50 # window size\nS = df.shape[1] # stock count\nfeature_count = 16 # feature count after first dense layer\nH = 16 # hidden size\nnum_epochs = 10 # number of epochs","metadata":{"_uuid":"889a48f9-e738-4ea1-9471-fe25d9c8e700","_cell_guid":"daa1bf60-47a4-45c6-b45e-487edf0b2854","trusted":true,"collapsed":false,"id":"wX4cVw7YKS0C","executionInfo":{"status":"ok","timestamp":1744936456593,"user_tz":-240,"elapsed":3,"user":{"displayName":"Vahagn Dovlatyan Univ 2","userId":"09643611316529200036"}},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-04-18T01:20:12.826904Z","iopub.execute_input":"2025-04-18T01:20:12.827692Z","iopub.status.idle":"2025-04-18T01:20:12.831730Z","shell.execute_reply.started":"2025-04-18T01:20:12.827667Z","shell.execute_reply":"2025-04-18T01:20:12.831017Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"train_dataset = StockDataset(train_returns, train_prices[1:], window_size=T, sharpe_window=R)\ntrain_dataloader = DataLoader(train_dataset, batch_size=B, shuffle=True)\n\nfor batch_data, batch_returns in train_dataloader:\n    print(batch_data.shape)\n    print(batch_returns.shape)\n    break\nprint(\"Length of train dataloader:\", len(train_dataloader))","metadata":{"_uuid":"8f9d7445-af34-40de-a25f-f098ec96c7df","_cell_guid":"8849cc2a-2ee8-48c9-b2fb-7113062a6273","trusted":true,"collapsed":false,"id":"NA76wLx7NGw9","executionInfo":{"status":"ok","timestamp":1744936460313,"user_tz":-240,"elapsed":92,"user":{"displayName":"Vahagn Dovlatyan Univ 2","userId":"09643611316529200036"}},"outputId":"268876a0-d0c1-45df-a6bc-5e748691ce42","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-04-18T01:20:15.926877Z","iopub.execute_input":"2025-04-18T01:20:15.927153Z","iopub.status.idle":"2025-04-18T01:20:15.994292Z","shell.execute_reply.started":"2025-04-18T01:20:15.927132Z","shell.execute_reply":"2025-04-18T01:20:15.993583Z"}},"outputs":[{"name":"stdout","text":"torch.Size([8, 30, 50, 505, 2])\ntorch.Size([8, 30, 505])\nLength of train dataloader: 368\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"val_dataset = StockDataset(val_returns, val_prices[1:], window_size=T, sharpe_window=R)\nval_dataloader = DataLoader(val_dataset, batch_size=B, shuffle=True)\n\nfor batch_data, batch_returns in val_dataloader:\n    print(batch_data.shape)\n    print(batch_returns.shape)\n    break\n\nprint(\"Length of validation dataloader:\", len(val_dataloader))","metadata":{"_uuid":"ac5bb83e-4e1b-4a87-8e4f-6aeaca4212c3","_cell_guid":"c279478b-b21f-4899-8b28-be10e456ba3f","trusted":true,"collapsed":false,"id":"Un5uf-pwJ7sf","executionInfo":{"status":"ok","timestamp":1744936461627,"user_tz":-240,"elapsed":180,"user":{"displayName":"Vahagn Dovlatyan Univ 2","userId":"09643611316529200036"}},"outputId":"d2bec420-cb4d-4790-8916-076996619913","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-04-18T01:20:17.165821Z","iopub.execute_input":"2025-04-18T01:20:17.166075Z","iopub.status.idle":"2025-04-18T01:20:17.218248Z","shell.execute_reply.started":"2025-04-18T01:20:17.166059Z","shell.execute_reply":"2025-04-18T01:20:17.217494Z"}},"outputs":[{"name":"stdout","text":"torch.Size([8, 30, 50, 505, 2])\ntorch.Size([8, 30, 505])\nLength of validation dataloader: 22\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"# test_dataset = StockDataset(test_returns, test_prices[1:], window_size=T, sharpe_window=R)\n# test_dataloader = DataLoader(test_dataset, batch_size=B, shuffle=True)\n\n# for batch_data, batch_returns in test_dataloader:\n#     print(batch_data.shape)\n#     print(batch_returns.shape)\n#     break\n\n# print(\"Length of test dataloader:\", len(test_dataloader))","metadata":{"_uuid":"96eba004-2700-4117-9e7c-ce54621b1169","_cell_guid":"24d68300-9c0b-41ac-abd1-929395d09256","trusted":true,"collapsed":false,"id":"amhfh4xJKLDT","executionInfo":{"status":"ok","timestamp":1744805929981,"user_tz":-240,"elapsed":139,"user":{"displayName":"Vahagn Dovlatyan Univ 2","userId":"09643611316529200036"}},"outputId":"66a7ce81-b5c4-407d-8aea-b506327a3dd1","jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Model construction.","metadata":{"_uuid":"79967a04-dfb9-4214-a6c8-a40f2dd148ec","_cell_guid":"7c9d7275-1b81-4f60-93e9-2b0f31e842e7","trusted":true,"collapsed":false,"id":"JGbBY7RWK_Vu","jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"class SharpeLSTMModel(nn.Module):\n    def __init__(self, num_classes=1, input_size=2, hidden_size=64, num_layers=1, feature_size=32):\n        super(SharpeLSTMModel, self).__init__()\n\n        self.num_classes = num_classes\n        self.input_size = input_size  # 2 features (returns and prices)\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        self.feature_size = feature_size\n\n        # Feature projection layer (2 -> feature_size)\n        self.feature_projection = nn.Linear(input_size, feature_size)\n\n        # LSTM layer\n        self.lstm = nn.LSTM(input_size=feature_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n\n        # Fully connected output layer (hidden_size -> 1)\n        self.fc = nn.Linear(hidden_size, 1)\n\n    def forward(self, x):\n        B, R, T, S, _ = x.shape\n\n        # Project features (Returns, Prices) into higher dimensionality (B, R, T, S, F)\n        x = self.feature_projection(x)  # (B, R, T, S, F)\n\n        # Reshape to (B*R*S, T, F) for LSTM\n        x = x.permute(0, 1, 3, 2, 4).reshape(B * R * S, T, self.feature_size)\n\n        # Pass through LSTM\n        lstm_out, _ = self.lstm(x)  # (B*R*S, T, H)\n\n        # Take output of last time step\n        final_out = lstm_out[:, -1, :]  # (B*R*S, H)\n\n        # Fully connected layer\n        dense_out = self.fc(final_out)  # (B*R*S, 1)\n\n        # Reshape back to (B, R, S)\n        dense_out = dense_out.view(B, R, S)  # (B, R, S)\n\n        # Apply softmax to get weights\n        weights = F.softmax(dense_out, dim=2)  # (B, R, S)\n\n        return weights\n\ndef sharpe_ratio_loss(weights, returns, epsilon=1e-6):\n    \"\"\"\n    weights: (B, R, S)\n    returns: (B, R, S)\n    \"\"\"\n    portfolio_returns = (weights * returns).sum(dim=2)  # (B, R)\n    mean = portfolio_returns.mean(dim=1)\n    std = portfolio_returns.std(dim=1) + epsilon\n    sharpe = mean / std\n    return -sharpe.mean()  # negative Sharpe to minimize","metadata":{"_uuid":"337e5001-7ede-427f-a610-1f5d90f238be","_cell_guid":"dddc62af-de8e-4937-b8c0-8b0d48eb9e6b","trusted":true,"collapsed":false,"id":"jykmdJ9Bsk9B","executionInfo":{"status":"ok","timestamp":1744930030971,"user_tz":-240,"elapsed":48,"user":{"displayName":"Vahagn Dovlatyan Univ 2","userId":"09643611316529200036"}},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-04-18T01:20:19.730779Z","iopub.execute_input":"2025-04-18T01:20:19.731309Z","iopub.status.idle":"2025-04-18T01:20:19.738417Z","shell.execute_reply.started":"2025-04-18T01:20:19.731286Z","shell.execute_reply":"2025-04-18T01:20:19.737589Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"model = SharpeLSTMModel(num_classes=1, input_size=2, hidden_size=H, num_layers=1, feature_size=feature_count).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4)","metadata":{"_uuid":"00aaf0db-713c-4288-a3c0-0de79ea772dd","_cell_guid":"026c6c8a-2322-4344-844f-d2c9b8e94040","trusted":true,"collapsed":false,"id":"WGeRIHIbVpJd","executionInfo":{"status":"ok","timestamp":1744936466094,"user_tz":-240,"elapsed":2,"user":{"displayName":"Vahagn Dovlatyan Univ 2","userId":"09643611316529200036"}},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-04-18T01:20:22.202610Z","iopub.execute_input":"2025-04-18T01:20:22.203198Z","iopub.status.idle":"2025-04-18T01:20:22.209297Z","shell.execute_reply.started":"2025-04-18T01:20:22.203177Z","shell.execute_reply":"2025-04-18T01:20:22.208746Z"}},"outputs":[],"execution_count":29},{"cell_type":"markdown","source":"Training.","metadata":{"_uuid":"daded44e-3efe-43fa-a6ac-ba2a80483643","_cell_guid":"87699149-61b0-445f-90eb-0f6ce6a0fb84","trusted":true,"collapsed":false,"id":"AStJNK8JgtOa","jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Training loop\ntrain_losses = []\nval_losses = []\nfor epoch in range(num_epochs):\n    model.train()  # Set the model to training mode\n    total_train_loss = 0.0\n    for batch_data, batch_returns in train_dataloader:\n        batch_data, batch_returns = batch_data.to(device), batch_returns.to(device)\n\n        optimizer.zero_grad()  # Reset gradients\n\n        # Forward pass\n        weights = model(batch_data)\n\n        # Compute training loss (Negative Sharpe ratio)\n        train_loss = sharpe_ratio_loss(weights, batch_returns)\n        total_train_loss += train_loss.item()\n\n        # Backward pass\n        train_loss.backward()\n\n        # Update parameters\n        optimizer.step()\n\n    avg_train_loss = total_train_loss / len(train_dataloader)  # Average training loss for the epoch\n    train_losses.append(avg_train_loss) # To plot after\n\n    # Validation phase (after each epoch)\n    model.eval()  # Set the model to evaluation mode\n    with torch.no_grad():  # No gradient calculation needed for validation\n        total_val_loss = 0.0\n        for batch_data, batch_returns in val_dataloader:\n            batch_data, batch_returns = batch_data.to(device), batch_returns.to(device)\n\n            # Forward pass (no gradients needed)\n            weights = model(batch_data)\n\n            # Compute validation loss (Negative Sharpe ratio)\n            val_loss = sharpe_ratio_loss(weights, batch_returns)\n            total_val_loss += val_loss.item()\n\n        avg_val_loss = total_val_loss / len(val_dataloader)  # Average validation loss for the epoch\n        val_losses.append(avg_val_loss)\n\n    # Print training and validation loss for the current epoch\n    print(f\"Epoch {epoch+1}: Training Loss = {avg_train_loss:.6f}, Validation Loss = {avg_val_loss:.6f}\")","metadata":{"_uuid":"e30fe4c9-0f00-45ab-858a-1b1f8ddbb37c","_cell_guid":"5f0a64a1-4fa8-4809-ac67-2578a41910d4","trusted":true,"collapsed":false,"id":"QyXyIXfvLyzD","executionInfo":{"status":"error","timestamp":1744936470988,"user_tz":-240,"elapsed":3578,"user":{"displayName":"Vahagn Dovlatyan Univ 2","userId":"09643611316529200036"}},"outputId":"5dc56119-5ee4-47f8-ab01-c8b99531b52d","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-04-18T01:20:24.364845Z","iopub.execute_input":"2025-04-18T01:20:24.365124Z","iopub.status.idle":"2025-04-18T01:20:25.162320Z","shell.execute_reply.started":"2025-04-18T01:20:24.365102Z","shell.execute_reply":"2025-04-18T01:20:25.161228Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_102/1176546763.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# Compute training loss (Negative Sharpe ratio)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_102/362264726.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# Pass through LSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (B*R*S, T, H)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# Take output of last time step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1123\u001b[0;31m             result = _VF.lstm(\n\u001b[0m\u001b[1;32m   1124\u001b[0m                 \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1125\u001b[0m                 \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 30.94 GiB. GPU 0 has a total capacity of 14.74 GiB of which 12.23 GiB is free. Process 13482 has 2.51 GiB memory in use. Of the allocated memory 2.34 GiB is allocated by PyTorch, and 49.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"],"ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 30.94 GiB. GPU 0 has a total capacity of 14.74 GiB of which 12.23 GiB is free. Process 13482 has 2.51 GiB memory in use. Of the allocated memory 2.34 GiB is allocated by PyTorch, and 49.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)","output_type":"error"}],"execution_count":30},{"cell_type":"code","source":"# Plotting train losses per epoch\nplt.figure(figsize=(10, 6))\nplt.plot(range(1, num_epochs + 1), train_losses, label=\"Training Loss\", color='blue')\nplt.plot(range(1, num_epochs + 1), val_losses, label=\"Validation Loss\", color='red')\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.title(\"Average Training and Validation Losses per Epoch\")\nplt.legend()\nplt.show()","metadata":{"_uuid":"5f96a76c-cb2b-4200-a0bb-b90eaa0df5bb","_cell_guid":"3cd76c49-fcaf-473c-8df6-32fc75f318ea","trusted":true,"collapsed":false,"id":"rnxLOGAjh3YK","executionInfo":{"status":"ok","timestamp":1744936058223,"user_tz":-240,"elapsed":188,"user":{"displayName":"Vahagn Dovlatyan Univ 2","userId":"09643611316529200036"}},"outputId":"cd7a54f5-52b9-4dd6-ab82-fdbe838ae6e7","jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Testing.","metadata":{"_uuid":"35e10b12-25d7-42d6-9acf-e919b94d0c8a","_cell_guid":"191d3a0e-8ae5-48bd-8d4a-181104ae9bce","trusted":true,"collapsed":false,"id":"JkgK2l_6gvtL","jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"cumulative_returns_test = [1]\ntesting_data = torch.stack([torch.tensor(test_prices[1:].values, dtype=torch.float32),\n                            torch.tensor(test_returns.values, dtype=torch.float32)], axis=2).to(device) # (days, S, 2)\ntesting_returns = torch.tensor(test_returns.values, dtype=torch.float32).to(device)\n\nprint(f\"testing_data: {testing_data.shape}, testing_returns: {testing_returns.shape}\")\nmodel.eval()\nwith torch.no_grad():\n    for t in range(T, testing_data.shape[0]):\n        weights = model(testing_data[t - T:t].reshape(1, 1, T, S, 2)) # (T, S, 2) -> (S)\n        next_day_return = weights @ testing_returns[t]\n        cumulative_returns_test.append(cumulative_returns_test[-1] * (1 + next_day_return))","metadata":{"_uuid":"1406ef18-1591-4511-98f9-5dc3ccd92440","_cell_guid":"756d2090-0d4f-4971-a3f3-61d6658d8861","trusted":true,"collapsed":false,"id":"sQshmJJJghVK","executionInfo":{"status":"ok","timestamp":1744936125982,"user_tz":-240,"elapsed":543,"user":{"displayName":"Vahagn Dovlatyan Univ 2","userId":"09643611316529200036"}},"outputId":"e2c3e82a-96e7-435a-c2b2-cf03bf62de3c","jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nplt.plot(test_prices[1:].index.values[T - 1:], np.array([r.cpu()[0][0] if r != 1 else r for r in cumulative_returns_test]), label='Cumulative Return')\nplt.title(\"Cumulative Return Over Time On Test Data\")\nplt.xlabel(\"Days\")\nplt.ylabel(\"Cumulative Return\")\nplt.legend()\nplt.grid(True)\nplt.show()","metadata":{"_uuid":"3233b82a-f063-4b62-a41e-bb6a91ee0ba5","_cell_guid":"042699a2-ca3a-4a80-ad79-7080c5998f1c","trusted":true,"collapsed":false,"id":"vR08E7-wGY2K","executionInfo":{"status":"ok","timestamp":1744936128224,"user_tz":-240,"elapsed":532,"user":{"displayName":"Vahagn Dovlatyan Univ 2","userId":"09643611316529200036"}},"outputId":"d8392e31-4e9f-45f0-d647-90bf71fd1730","jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"Allocated: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")\nprint(f\"Cached:    {torch.cuda.memory_reserved() / 1e9:.2f} GB\")","metadata":{"_uuid":"72bf5ffc-da11-4f1b-9975-554c611a8052","_cell_guid":"7bd9e0c5-6db4-4d36-98b7-67dadbd5eb20","trusted":true,"collapsed":false,"id":"BpoV4PGYSMKe","executionInfo":{"status":"ok","timestamp":1744809359401,"user_tz":-240,"elapsed":11,"user":{"displayName":"Vahagn Dovlatyan Univ 2","userId":"09643611316529200036"}},"outputId":"3d50b014-30d6-41bd-c0fe-92632605e321","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-04-18T01:20:37.480606Z","iopub.execute_input":"2025-04-18T01:20:37.481073Z","iopub.status.idle":"2025-04-18T01:20:37.485775Z","shell.execute_reply.started":"2025-04-18T01:20:37.481050Z","shell.execute_reply":"2025-04-18T01:20:37.484966Z"}},"outputs":[{"name":"stdout","text":"Allocated: 0.51 GB\nCached:    0.55 GB\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"_uuid":"d789780b-099b-4c88-aaac-9e5240315ff5","_cell_guid":"753acba4-0149-4cf4-85d4-e88a67005cb6","trusted":true,"collapsed":false,"id":"mbme7WRzRdu6","executionInfo":{"status":"ok","timestamp":1744936440691,"user_tz":-240,"elapsed":48,"user":{"displayName":"Vahagn Dovlatyan Univ 2","userId":"09643611316529200036"}},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-04-18T01:20:36.621765Z","iopub.execute_input":"2025-04-18T01:20:36.622252Z","iopub.status.idle":"2025-04-18T01:20:36.716295Z","shell.execute_reply.started":"2025-04-18T01:20:36.622229Z","shell.execute_reply":"2025-04-18T01:20:36.715583Z"}},"outputs":[],"execution_count":32}]}